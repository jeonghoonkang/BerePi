import os
import io
import subprocess
import numpy as np
import streamlit as st
from openai import OpenAI
from PyPDF2 import PdfReader


def get_gpu_info() -> str:
    try:
        out = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=name", "--format=csv,noheader"],
            stderr=subprocess.DEVNULL,
        )
        gpus = out.decode().strip().split("\n")
        gpus = [g for g in gpus if g]
        return ", ".join(gpus) if gpus else "GPU ì—†ìŒ"
    except Exception:
        return "GPU ì—†ìŒ"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    key_candidates = [
        os.path.join(os.path.dirname(__file__), "nocommit_key.txt"),
        os.path.join(os.path.dirname(os.path.dirname(__file__)), "nocommit_key.txt"),
    ]
    for cand in key_candidates:
        if os.path.isfile(cand):
            try:
                with open(cand, "r", encoding="utf-8") as f:
                    OPENAI_API_KEY = f.read().strip()
                break
            except Exception:
                pass

client = OpenAI(api_key=OPENAI_API_KEY)

st.set_page_config(page_title="PDF RAG Chat")
st.title("ðŸ“„ PDF ê¸°ë°˜ Q&A")
st.write(f"ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {get_gpu_info()}")
st.write("ì‚¬ìš© ëª¨ë¸: gpt-3.5-turbo")

if "docs" not in st.session_state:
    st.session_state.docs = None
    st.session_state.embs = None
    st.session_state.pdf_text = ""


def read_pdf(file) -> str:
    text = ""
    reader = PdfReader(file)
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return text


def chunk_text(text: str, chunk_size: int = 200, overlap: int = 50):
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        chunk = " ".join(words[start : start + chunk_size])
        chunks.append(chunk)
        start += chunk_size - overlap
    return chunks



uploaded_file = st.file_uploader("PDF ì—…ë¡œë“œ", type="pdf")
mode = st.radio("ë‹µë³€ ëª¨ë“œ", ["ê¸°ë³¸", "PDF ì‚¬ìš©"])

if uploaded_file:
    text = read_pdf(uploaded_file)
    st.session_state.pdf_text = text
    st.session_state.docs = chunk_text(text)
    st.session_state.embs = []
    with st.spinner("ìž„ë² ë”© ìƒì„± ì¤‘..."):
        for chunk in st.session_state.docs:
            resp = client.embeddings.create(
                model="text-embedding-3-small",
                input=[chunk],
            )
            st.session_state.embs.append(np.array(resp.data[0].embedding))
    st.success("ë¬¸ì„œ ë¡œë”© ì™„ë£Œ")

st.markdown("---")
question = st.text_input("ì§ˆë¬¸ ìž…ë ¥")

if question:
    default_box = st.container()
    pdf_box = st.container()
    text_box = st.container()

    with default_box:
        st.subheader("1. ê¸°ë³¸ ë‹µë³€")
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            resp = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": question}],
            )
            st.write(resp.choices[0].message.content)

    with pdf_box:
        st.subheader("2. PDF ê¸°ë°˜ ë‹µë³€")
        if mode == "PDF ì‚¬ìš©":
            if st.session_state.docs:
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    q_emb = np.array(
                        client.embeddings.create(
                            model="text-embedding-3-small", input=[question]
                        ).data[0].embedding
                    )
                    sims = [
                        float(
                            np.dot(q_emb, e)
                            / (np.linalg.norm(q_emb) * np.linalg.norm(e))
                        )
                        for e in st.session_state.embs
                    ]
                    top_indices = np.argsort(sims)[-3:][::-1]
                    context = "\n\n".join(
                        st.session_state.docs[i] for i in top_indices
                    )
                    prompt = (
                        "ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\në¬¸ì„œ ë‚´ìš©:\n"
                        + context
                        + "\n\nì§ˆë¬¸: "
                        + question
                    )
                    resp = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": prompt}],
                    )
                    st.write(resp.choices[0].message.content)
            else:
                st.warning("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    with text_box:
        st.subheader("3. PDF ë‚´ìš©")
        if st.session_state.pdf_text:
            st.text_area("", st.session_state.pdf_text, height=300)

